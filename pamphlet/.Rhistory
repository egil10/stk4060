for (country in unique_countries) {
country_data <- df_clean %>% filter(Country == country)
latest <- country_data %>% filter(Year == max(Year, na.rm = TRUE))
json_output <- list(
title = "Average Annual Hours Actually Worked Per Worker",
description = paste0(
"Average annual hours actually worked per worker in ",
country, ", latest available year (", latest$Year[1], ")"
),
unit = unique(country_data$Unit)[1],
source = "https://stats.oecd.org/Index.aspx?DataSetCode=SAE",
data = list(
country = list(
value = as.numeric(latest$Value[1]),
unit = unique(country_data$Unit)[1]
)
)
)
# Write JSON file
json_file_name <- paste0("json_countries/", gsub(" ", "_", country), ".json")
write_json(json_output, json_file_name, pretty = TRUE, auto_unbox = TRUE)
}
cat("✅ JSON files generated for", length(unique_countries), "countries in /json_countries\n")
# === Required packages ===
library(readr)
library(dplyr)
library(jsonlite)
# === 1. Read data ===
# Replace with your actual file path
df <- read_csv("data/oecds.csv", show_col_types = FALSE)
# === 2. Keep relevant columns ===
df_clean <- df %>%
select(`Reference area`, REF_AREA, TIME_PERIOD, OBS_VALUE, `Unit of measure`) %>%
rename(
Country = `Reference area`,
Year = TIME_PERIOD,
Value = OBS_VALUE,
Unit = `Unit of measure`
) %>%
filter(!is.na(Value))
# === 3. Keep only latest year per country ===
latest_data <- df_clean %>%
group_by(Country) %>%
filter(Year == max(Year, na.rm = TRUE)) %>%
ungroup()
# === 4. Build JSON structure ===
data_list <- setNames(
lapply(seq_len(nrow(latest_data)), function(i) {
list(
value = as.numeric(latest_data$Value[i]),
unit = latest_data$Unit[i]
)
}),
latest_data$Country
)
json_output <- list(
title = "Average Annual Hours Actually Worked Per Worker",
description = paste0(
"Latest available year of average annual hours actually worked per worker, OECD dataset (as of ",
max(latest_data$Year, na.rm = TRUE),
")"
),
unit = unique(latest_data$Unit)[1],
source = "https://stats.oecd.org/Index.aspx?DataSetCode=SAE",
data = data_list
)
# === 5. Write JSON file ===
write_json(json_output, "oecd_hours_latest.json", pretty = TRUE, auto_unbox = TRUE)
cat("✅ JSON file 'oecd_hours_latest.json' generated successfully!\n")
# === Required packages ===
library(readr)
library(dplyr)
library(jsonlite)
# === 1. Read data ===
# Replace with your actual file path
df <- read_csv("data/oecds.csv", show_col_types = FALSE)
# === 2. Keep relevant columns ===
df_clean <- df %>%
select(`Reference area`, REF_AREA, TIME_PERIOD, OBS_VALUE, `Unit of measure`) %>%
rename(
Country = `Reference area`,
Year = TIME_PERIOD,
Value = OBS_VALUE,
Unit = `Unit of measure`
) %>%
filter(!is.na(Value))
# === 3. Keep only latest year per country ===
latest_data <- df_clean %>%
group_by(Country) %>%
filter(Year == max(Year, na.rm = TRUE)) %>%
ungroup()
# === 4. Build JSON structure ===
data_list <- setNames(
lapply(seq_len(nrow(latest_data)), function(i) {
list(
value = as.numeric(latest_data$Value[i]),
unit = latest_data$Unit[i]
)
}),
latest_data$Country
)
json_output <- list(
title = "Average Annual Hours Actually Worked Per Worker",
description = paste0(
"Latest available year of average annual hours actually worked per worker, OECD dataset (as of ",
max(latest_data$Year, na.rm = TRUE),
")"
),
unit = unique(latest_data$Unit)[1],
source = "https://stats.oecd.org/Index.aspx?DataSetCode=SAE",
data = data_list
)
# === 5. Write JSON file ===
write_json(json_output, "oecd_hours_latest.json", pretty = TRUE, auto_unbox = TRUE)
cat("✅ JSON file 'oecd_hours_latest.json' generated successfully!\n")
# === Load libraries ===
library(jsonlite)
library(dplyr)
library(purrr)
# === 1. Read Nobel JSON ===
# If saved locally:
# nobel <- fromJSON("nobel_laureates.json", flatten = TRUE)
# Or directly from the API:
nobel <- fromJSON("https://api.nobelprize.org/2.1/laureates?format=json", flatten = TRUE)
laureates <- nobel$laureates
# === 2. Extract relevant fields ===
# Some laureates may have missing birth info or multiple prizes
df <- map_dfr(laureates, function(x) {
tibble(
id = x$id %||% NA_character_,
name = x$fullName.en %||% x$knownName.en %||% NA_character_,
country = x$birth.place.country.en %||% NA_character_,
city = x$birth.place.city.en %||% NA_character_,
birth_year = substr(x$birth.date %||% NA_character_, 1, 4),
gender = x$gender %||% NA_character_,
prize_year = if (!is.null(x$nobelPrizes[[1]]$awardYear)) x$nobelPrizes[[1]]$awardYear else NA_character_,
category = if (!is.null(x$nobelPrizes[[1]]$category.en)) x$nobelPrizes[[1]]$category.en else NA_character_,
motivation = if (!is.null(x$nobelPrizes[[1]]$motivation.en)) x$nobelPrizes[[1]]$motivation.en else NA_character_,
institution = if (!is.null(x$nobelPrizes[[1]]$affiliations[[1]]$name.en)) x$nobelPrizes[[1]]$affiliations[[1]]$name.en else NA_character_,
wikipedia = x$wikipedia.english %||% NA_character_,
wikidata = x$wikidata.url %||% NA_character_
)
})
"USA": {
"name": "Claudia Goldin",
"USA": {
"name": "Claudia Goldin",
# Load packages
library(jsonlite)
library(dplyr)
library(purrr)
# === 1. Read local Nobel laureates data ===
nobel <- fromJSON("data/laureates.json")
laureates <- nobel$laureates
# === 2. Helper for safe extraction ===
safe_extract <- function(x, path, default = NA_character_) {
tryCatch({
val <- purrr::pluck(x, !!!path)
if (is.null(val) || length(val) == 0) default else as.character(val)
}, error = function(e) default)
}
# === 3. Extract key fields per laureate ===
df <- map_dfr(laureates, function(x) {
tibble(
id = safe_extract(x, c("id")),
name = coalesce(
safe_extract(x, c("fullName", "en")),
safe_extract(x, c("knownName", "en"))
),
country = safe_extract(x, c("birth", "place", "country", "en")),
birth_year = substr(safe_extract(x, c("birth", "date")), 1, 4),
gender = safe_extract(x, c("gender")),
prize_year = safe_extract(x, c("nobelPrizes", 1, "awardYear")),
category = safe_extract(x, c("nobelPrizes", 1, "category", "en")),
motivation = safe_extract(x, c("nobelPrizes", 1, "motivation", "en")),
institution = safe_extract(x, c("nobelPrizes", 1, "affiliations", 1, "name", "en")),
wikipedia = safe_extract(x, c("wikipedia", "english")),
wikidata = safe_extract(x, c("wikidata", "url"))
)
})
# === 4. Keep the most recent laureate per country ===
df_clean <- df %>%
filter(!is.na(country) & !is.na(name)) %>%
mutate(prize_year = suppressWarnings(as.numeric(prize_year))) %>%
group_by(country) %>%
arrange(desc(prize_year)) %>%
slice_head(n = 1) %>%
ungroup()
# === 5. Build JSON ===
data_list <- setNames(
lapply(seq_len(nrow(df_clean)), function(i) {
list(
name = df_clean$name[i],
prize_year = df_clean$prize_year[i],
category = df_clean$category[i],
motivation = df_clean$motivation[i],
institution = df_clean$institution[i],
wikipedia = df_clean$wikipedia[i],
wikidata = df_clean$wikidata[i]
)
}),
df_clean$country
)
json_output <- list(
title = "Latest Nobel Prize Laureates by Country",
description = "Each country's most recent Nobel laureate, with award year, category, motivation, and institution.",
source = "https://api.nobelprize.org/2.1/laureates",
data = data_list
)
# === 6. Write to file ===
dir.create("output", showWarnings = FALSE)
write_json(json_output, "output/nobel_latest_by_country.json", pretty = TRUE, auto_unbox = TRUE)
cat("✅ JSON file saved to output/nobel_latest_by_country.json\n")
# Load libraries
library(jsonlite)
library(dplyr)
library(purrr)
# === 1. Read local Nobel laureates file ===
nobel <- fromJSON("data/laureates.json")
laureates <- nobel$laureates
# === 2. Safely extract country name ===
safe_extract <- function(x, path, default = NA_character_) {
tryCatch({
val <- purrr::pluck(x, !!!path)
if (is.null(val) || length(val) == 0) default else as.character(val)
}, error = function(e) default)
}
# === 3. Build dataframe of countries ===
df <- map_dfr(laureates, function(x) {
tibble(
country = safe_extract(x, c("birth", "place", "country", "en"))
)
}) %>%
filter(!is.na(country)) %>%
group_by(country) %>%
summarise(value = n(), .groups = "drop")
# === 4. Build JSON ===
data_list <- setNames(
lapply(seq_len(nrow(df)), function(i) {
list(
value = df$value[i],
unit = "laureates"
)
}),
df$country
)
json_output <- list(
title = "Number of Nobel Laureates by Country",
description = "Total count of Nobel Prize laureates by country of birth (all years)",
unit = "laureates",
source = "https://api.nobelprize.org/2.1/laureates",
data = data_list
)
# === 5. Write to file ===
dir.create("output", showWarnings = FALSE)
write_json(json_output, "output/nobel_laureates_by_country.json", pretty = TRUE, auto_unbox = TRUE)
cat("✅ File saved to output/nobel_laureates_by_country.json\n")
library(jsonlite)
library(dplyr)
library(purrr)
# === 1. Read local Nobel laureates file ===
nobel <- fromJSON("data/laureates.json")
laureates <- nobel$laureates
# === 2. Helper for safe extraction ===
safe_extract <- function(x, paths) {
for (path in paths) {
val <- tryCatch(purrr::pluck(x, !!!path), error = function(e) NULL)
if (!is.null(val) && length(val) > 0 && !is.na(val)) return(as.character(val))
}
return(NA_character_)
}
# === 3. Try multiple possible country paths ===
df <- map_dfr(laureates, function(x) {
tibble(
country = safe_extract(x, list(
c("birth", "place", "country", "en"),
c("birth", "place", "countryNow", "en"),
c("birth", "place", "country", "no"),
c("birth", "place", "country", "se")
))
)
})
# === 4. Count laureates per country ===
df_clean <- df %>%
filter(!is.na(country) & country != "") %>%
group_by(country) %>%
summarise(value = n(), .groups = "drop")
# === 5. Build JSON ===
data_list <- setNames(
lapply(seq_len(nrow(df_clean)), function(i) {
list(
value = df_clean$value[i],
unit = "laureates"
)
}),
df_clean$country
)
json_output <- list(
title = "Number of Nobel Laureates by Country",
description = "Total count of Nobel Prize laureates by country of birth (all years)",
unit = "laureates",
source = "https://api.nobelprize.org/2.1/laureates",
data = data_list
)
# === 6. Write to file ===
dir.create("output", showWarnings = FALSE)
write_json(json_output, "output/nobel_laureates_by_country.json", pretty = TRUE, auto_unbox = TRUE)
cat("✅ Nobel laureates by country saved to output/nobel_laureates_by_country.json\n")
library(tidyverse)
library(astsa)
library(xts)
filter = stats::filter
lag = stats::lag
# -------------------------------------------------------------------------
# ma
pdf("plots/mva.pdf", height = 12, width = 6)
w = rnorm(250) # 250 N(0,1) variates
v = filter(w, sides=2, filter=rep(1/3,3)) # moving average
par(mfrow=2:1)
tsplot(w, main="white noise", col=4, gg=TRUE)
tsplot(v, ylim=c(-3,3), main="moving average", col=4, gg=TRUE)
dev.off()
# recursive
pdf("plots/recur.pdf", height = 12, width = 6)
w = rnorm(300) # 50 extra to avoid startup problems
x = filter(w, filter=c(1.5,-.75), method="recursive")[-(1:50)]
tsplot(x, main="autoregression", col=4, gg=TRUE)
dev.off()
# rd w drift
pdf("plots/rwd.pdf", height = 12, width = 6)
par(mfrow = c(1, 1))
set.seed(154) # so you can reproduce the results
w = rnorm(200); x = cumsum(w) # two commands in one line
wd = w +.2; xd = cumsum(wd)
tsplot(xd, ylim=c(-5,55), main="random walk", ylab="", col=4, gg=TRUE)
lines(x, col=6); clip(0, 200, 0, 50)
abline(h=0, a=0, b=.2, col=8, lty=5)
dev.off()
# hawaii!
par(mfrow = c(4,1))
x = window(hor, start=2002)
out = stl(x, s.window=15)$time.series
tsplot(x, main="Hawaiian Occupancy Rate", ylab="% rooms", col=8, type="c")
text(x, labels=1:4, col=c(3,4,2,6), cex=1.25)
tsplot(out[,1], main="Seasonal", ylab="% rooms", col=8, type="c")
text(out[,1], labels=1:4, col=c(3,4,2,6), cex=1.25)
tsplot(out[,2], main="Trend", ylab="% rooms", col=8, type="c")
text(out[,2], labels=1:4, col=c(3,4,2,6), cex=1.25)
tsplot(out[,3], main="Noise", ylab="% rooms", col=8, type="c")
text(out[,3], labels=1:4, col=c(3,4,2,6), cex=1.25)
library(tidyverse)
library(astsa)
library(xts)
filter = stats::filter
lag = stats::lag
# -------------------------------------------------------------------------
# ma
pdf("plots/mva.pdf", height = 12, width = 6)
w = rnorm(250) # 250 N(0,1) variates
v = filter(w, sides=2, filter=rep(1/3,3)) # moving average
par(mfrow=2:1)
tsplot(w, main="white noise", col=4, gg=TRUE)
tsplot(v, ylim=c(-3,3), main="moving average", col=4, gg=TRUE)
dev.off()
# recursive
pdf("plots/recur.pdf", height = 12, width = 6)
w = rnorm(300) # 50 extra to avoid startup problems
x = filter(w, filter=c(1.5,-.75), method="recursive")[-(1:50)]
tsplot(x, main="autoregression", col=4, gg=TRUE)
dev.off()
# rd w drift
pdf("plots/rwd.pdf", height = 12, width = 6)
par(mfrow = c(1, 1))
set.seed(154) # so you can reproduce the results
w = rnorm(200); x = cumsum(w) # two commands in one line
wd = w +.2; xd = cumsum(wd)
tsplot(xd, ylim=c(-5,55), main="random walk", ylab="", col=4, gg=TRUE)
lines(x, col=6); clip(0, 200, 0, 50)
abline(h=0, a=0, b=.2, col=8, lty=5)
dev.off()
# hawaii!
pdf("plots/hawaii.pdf", height = 12, width = 6)
par(mfrow = c(4,1))
x = window(hor, start=2002)
out = stl(x, s.window=15)$time.series
tsplot(x, main="Hawaiian Occupancy Rate", ylab="% rooms", col=8, type="c")
text(x, labels=1:4, col=c(3,4,2,6), cex=1.25)
tsplot(out[,1], main="Seasonal", ylab="% rooms", col=8, type="c")
text(out[,1], labels=1:4, col=c(3,4,2,6), cex=1.25)
tsplot(out[,2], main="Trend", ylab="% rooms", col=8, type="c")
text(out[,2], labels=1:4, col=c(3,4,2,6), cex=1.25)
tsplot(out[,3], main="Noise", ylab="% rooms", col=8, type="c")
text(out[,3], labels=1:4, col=c(3,4,2,6), cex=1.25)
dev.off()
setwd("C:/Users/ofurn/Dokumenter/Github/stk4060/pamphlet")
library(tidyverse)
library(astsa)
library(tidyverse)
library(astsa)
# -------------------------------------------------------------------------
t <- seq(-10,10,0.01)
A <- 1 # amplitued
phi <- 0.33 # phase
omega <- 1/10 # frequency
x <- A*cos(2*pi*omega*t + phi)
postscript("spectral_plot1.eps")
par(mfrow=c(1,1))
plot(t,x,type="l",lwd=2,frame.plot=FALSE)
tobs <- seq(min(t),max(t),1)
xobs <- x[t%in%tobs]
points(tobs,xobs,col="magenta",pch=1)
abline(A,0,col="cornflowerblue",lwd=2);abline(-A,0,col="cornflowerblue",lwd=2)
dev.off()
library(tidyverse)
library(astsa)
# -------------------------------------------------------------------------
t <- seq(-10,10,0.01)
A <- 1 # amplitued
phi <- 0.33 # phase
omega <- 1/10 # frequency
x <- A*cos(2*pi*omega*t + phi)
postscript("spectral_plot1.eps")
par(mfrow=c(1,1))
plot(t,x,type="l",lwd=2,frame.plot=FALSE)
tobs <- seq(min(t),max(t),1)
xobs <- x[t%in%tobs]
points(tobs,xobs,col="magenta",pch=1)
abline(A,0,col="cornflowerblue",lwd=2);abline(-A,0,col="cornflowerblue",lwd=2)
t <- seq(-10,10,0.01)
A <- 1 # amplitued
phi <- 0.33 # phase
omega <- 1/10 # frequency
x <- A*cos(2*pi*omega*t + phi)
postscript("spectral_plot1.eps")
par(mfrow=c(1,1))
plot(t,x,type="l",lwd=2,frame.plot=FALSE)
plot(t,x,type="l",lwd=2)
tobs <- seq(min(t),max(t),1)
xobs <- x[t%in%tobs]
points(tobs,xobs,col="magenta",pch=1)
abline(A,0,col="cornflowerblue",lwd=2);abline(-A,0,col="cornflowerblue",lwd=2)
library(tidyverse)
library(astsa)
# -------------------------------------------------------------------------
pdf("plots/spectral.pdf", height = 12, width = 6)
t <- seq(-10,10,0.01)
A <- 1 # amplitued
phi <- 0.33 # phase
omega <- 1/10 # frequency
x <- A*cos(2*pi*omega*t + phi)
postscript("spectral_plot1.eps")
par(mfrow=c(1,1))
plot(t,x,type="l",lwd=2)
tobs <- seq(min(t),max(t),1)
xobs <- x[t%in%tobs]
points(tobs,xobs,col="magenta",pch=1)
abline(A,0,col="cornflowerblue",lwd=2);abline(-A,0,col="cornflowerblue",lwd=2)
dev.off()
library(tidyverse)
library(astsa)
# -------------------------------------------------------------------------
# Create PDF
pdf("plots/spectral.pdf", height = 12, width = 6)
t <- seq(-10, 10, 0.01)
A <- 1
phi <- 0.33
omega <- 1/10
x <- A * cos(2*pi*omega*t + phi)
par(mfrow=c(1,1))
plot(t, x, type="l", lwd=2)
tobs <- seq(min(t), max(t), 1)
xobs <- x[match(tobs, t)]   # safer than x[t %in% tobs]
points(tobs, xobs, col="magenta", pch=1)
abline(h =  A, col="cornflowerblue", lwd=2)
abline(h = -A, col="cornflowerblue", lwd=2)
dev.off()
# -------------------------------------------------------------------------
# Optional: Create EPS separately
postscript("plots/spectral_plot1.eps", height = 12, width = 6)
par(mfrow=c(1,1))
plot(t, x, type="l", lwd=2)
points(tobs, xobs, col="magenta", pch=1)
abline(h =  A, col="cornflowerblue", lwd=2)
abline(h = -A, col="cornflowerblue", lwd=2)
dev.off()
library(tidyverse)
library(astsa)
# -------------------------------------------------------------------------
# Create PDF
pdf("plots/spectral.pdf", height = 12, width = 6)
t <- seq(-10, 10, 0.01)
A <- 1
phi <- 0.33
omega <- 1/10
x <- A * cos(2*pi*omega*t + phi)
par(mfrow=c(1,1))
plot(t, x, type="l", lwd=2)
tobs <- seq(min(t), max(t), 1)
xobs <- x[match(tobs, t)]   # safer than x[t %in% tobs]
points(tobs, xobs, col="magenta", pch=1)
abline(h =  A, col="cornflowerblue", lwd=2)
abline(h = -A, col="cornflowerblue", lwd=2)
dev.off()
# -------------------------------------------------------------------------
# Optional: Create EPS separately
postscript("plots/spectral_plot1.eps", height = 12, width = 6)
par(mfrow=c(1,1))
plot(t, x, type="l", lwd=2)
points(tobs, xobs, col="magenta", pch=1)
abline(h =  A, col="cornflowerblue", lwd=2)
abline(h = -A, col="cornflowerblue", lwd=2)
dev.off()
